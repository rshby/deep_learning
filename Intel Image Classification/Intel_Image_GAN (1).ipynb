{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intel Image - GAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OgNFA5D_W1x"
      },
      "source": [
        "# Install Package yang diperlukan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CqX7vVE_CD9"
      },
      "source": [
        "!pip install jcopdl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbNFzxvy_aKs"
      },
      "source": [
        "# Import Package yang diperlukan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygVtw_WT_jlf",
        "outputId": "c2d933d9-cc42-47cb-a4ba-d37a7f271bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from jcopdl.layers import linear_block\n",
        "from torch import nn\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from jcopdl.callback import Callback, set_config\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiCUGjWT_kN_"
      },
      "source": [
        "# Datasets dan DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw6UUOLUAB4h"
      },
      "source": [
        "# Download Datasets\n",
        "!unrar x \"/content/drive/My Drive/datasets/Intel_Image_Classification.rar\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjRHwVF7_m_w"
      },
      "source": [
        "bs = 256\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize supaya menjadi -1 sampai 1, supaya lebih stabil\n",
        "])\n",
        "\n",
        "train_set = datasets.ImageFolder(\"/content/Intel_Image_Classification/train/\", transform=data_transform)\n",
        "trainloader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=8)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWL7YQEAF7k",
        "outputId": "ce09ee90-18da-487b-c3b3-c6b66e4b2ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "image, label = next(iter(trainloader))\n",
        "image.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3, 150, 150])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymSIPAu2Ctud"
      },
      "source": [
        "# Set Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clWooki5AHzu"
      },
      "source": [
        "# set config\n",
        "config = set_config({\n",
        "    \"z_dim\" : 512,\n",
        "    \"bs\" :256\n",
        "})"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbDN67m_CyJ4"
      },
      "source": [
        "# Training Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw1mH1_iCmYo"
      },
      "source": [
        "from model_gan import Discriminator, Generator"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQy-ouOlCsTq"
      },
      "source": [
        "D_model = Discriminator().to(device)\n",
        "G_model = Generator(config.z_dim).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "d_optimizer = optim.Adam(D_model.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(G_model.parameters(), lr=0.0002)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hrKRkmUC_Wv"
      },
      "source": [
        "# Proses Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg9YOjJtC-Vg"
      },
      "source": [
        "import os\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "os.makedirs(\"output/GAN/\", exist_ok=True)\n",
        "os.makedirs(\"model/GAN/\", exist_ok=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYSwE2HHDGuq",
        "outputId": "42a65812-95a2-4d1d-bfb1-2c2696c5ca15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        }
      },
      "source": [
        "num_epochs = 200\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    D_model.train()\n",
        "    G_model.train()\n",
        "    \n",
        "    for real_image, _ in trainloader:\n",
        "        jumlah_data = real_image.shape[0]\n",
        "        \n",
        "        # Handle Real image dan Fake image\n",
        "        real_image = real_image.to(device)\n",
        "        fake_image = G_model.generate(jumlah_data, device)\n",
        "        \n",
        "        # Handle Real label dan Fake label\n",
        "        real_label = torch.ones((jumlah_data, 3), device=device)\n",
        "        fake_label = torch.zeros((jumlah_data, 3), device=device)\n",
        "        \n",
        "        # Training Discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        ## 1. Real image -> Discriminator -> label real\n",
        "        output = D_model(real_image)\n",
        "        d_real_loss = criterion(output, real_label)\n",
        "        \n",
        "        ## 2. Fake image -> Discriminator -> label fake\n",
        "        output = D_model(fake_image.detach())\n",
        "        d_fake_loss = criterion(output, fake_label)\n",
        "        \n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        # Training Generator\n",
        "        g_optimizer.zero_grad()\n",
        "        ## Fake image -> Discriminator -> label real -> jangan di detach()\n",
        "        output = D_model(fake_image)\n",
        "        g_loss = criterion(output, real_label)\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        \n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch: {epoch:5} | D_loss: {d_loss/2:.5f} | G_loss: {g_loss/2:.5f}\")\n",
        "        \n",
        "    if epoch % 20 == 0:\n",
        "        G.eval()\n",
        "        epoch = str(epoch).zfill(4)\n",
        "        fake_image = G_model.generate(64, device)\n",
        "        save_image(fake_image.view(-1, 3, 150, 150), f\"output/GAN/{epoch}.jpg\", nrow=8, normalize=True)\n",
        "        \n",
        "        #save model\n",
        "        torch.save(D, \"model/GAN/discriminator.pth\")\n",
        "        torch.save(G, \"model/GAN/generator.pth\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5e5b63e5514d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mG_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mreal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mjumlah_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 84, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 84, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 150, 150] at entry 0 and [3, 143, 150] at entry 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WCpcicRES_B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}